{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead73f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc193e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86288027",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('data', 'train_sets', '*', '*.jpg')\n",
    "fname = glob(path)\n",
    "\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a0270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label = []\n",
    "# for fn in fname :\n",
    "#     fn = fn.split(\"/\")[2]\n",
    "#     label.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e50141",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [fn.split(\"/\")[-2] for fn in fname]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1818c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [fn.split(\"/\")[-1] for fn in fname]\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a222f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(label)\n",
    "ints = np.arange(0, len(labels))\n",
    "dicts = dict(zip(labels, ints))\n",
    "\n",
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca257450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batik = pd.DataFrame({\"image_id\":images,\"label\":label})\n",
    "\n",
    "#check image files\n",
    "index = []\n",
    "path = path[:-7]\n",
    "for i in range(len(df_batik)) :\n",
    "    try :\n",
    "        Image.open(path + str(df_batik[\"label\"][i]) + '/' + str(df_batik[\"image_id\"][i]))\n",
    "        pass\n",
    "    except PIL.UnidentifiedImageError:\n",
    "        index.append(i)\n",
    "\n",
    "df = df_batik.drop(index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c2730",
   "metadata": {},
   "source": [
    "## Plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a8723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target, count = np.unique(df['label'], return_counts=True)\n",
    "precentange = [x / np.sum(count) for x in count]\n",
    "plt.style.use('seaborn')\n",
    "plt.pie(precentange, labels = target,  autopct='%1.f%%', shadow=True)\n",
    "plt.title('DATA PERCENTAGE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74578e4",
   "metadata": {},
   "source": [
    "## Datasets dan dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68ca1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a90816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Batik(Dataset) :\n",
    "    def __init__(self, x, y, path, map_label = dicts, transform=None) :\n",
    "        super().__init__()\n",
    "        self.X = x\n",
    "        self.y = y\n",
    "        self.path = path\n",
    "        self.map_label = map_label\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        img = Image.open(path + str(self.y[idx]) + '/' + str(self.X[idx])).convert(\"RGB\")\n",
    "        label = self.map_label[self.y[idx]]\n",
    "        \n",
    "        if self.transform is not None :\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce82127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7912c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df[\"image_id\"].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# train data, validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y , test_size=0.3, shuffle=True, \n",
    "                                                          stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79ed09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DATALOADER\n",
    "bath_size = 32\n",
    "crop_size = 128\n",
    "\n",
    "#pipeline data augmentation \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(crop_size, scale=(0.8, 1.0)),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(0, shear=(10)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(135),\n",
    "    transforms.CenterCrop(crop_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_set = Batik(X_train, y_train, path, transform=train_transform)\n",
    "val_set = Batik(X_val, y_val, path, transform=val_transform)\n",
    "\n",
    "# use pytorch for dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=bath_size, shuffle=True, \n",
    "                          num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=bath_size, shuffle=True, \n",
    "                        num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90cc154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Data\n",
    "## for predict\n",
    "\n",
    "test_set = datasets.ImageFolder('data/test_train/', transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be5dfe",
   "metadata": {},
   "source": [
    "## error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57acfa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature, target = next(iter(train_loader))\n",
    "# feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e6428",
   "metadata": {},
   "source": [
    "### Cek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5a7e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee8448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "int_label = dict(zip(ints, labels))\n",
    "\n",
    "\n",
    "img, label = train_set[random.randint(0, len(X_train))]\n",
    "plt.imshow(img.permute(1,2,0));\n",
    "print(int_label[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d8094b",
   "metadata": {},
   "source": [
    "## model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9174c8ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=7),\n",
    "            nn.LogSoftmax(1)\n",
    "        )\n",
    "    def forward(self, x) :\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c3962",
   "metadata": {},
   "source": [
    "### Early-Stopping Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16efa895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping() :\n",
    "    #    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    def __init__(self, patience=5, delta=0, verbose= False, path='checkpoint.pt', trace_func=print) :\n",
    "        \n",
    "        #Args:\n",
    "        #   patience (int): How long to wait after last time validation loss improved.\n",
    "        #                    Default: 7\n",
    "        #    verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "        #                    Default: False\n",
    "        #    delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "        #                    Default: 0\n",
    "        #    path (str): Path for the checkpoint to be saved to.\n",
    "        #                    Default: 'checkpoint.pt'\n",
    "        #    trace_func (function): trace print function.\n",
    "        #                    Default: print            \n",
    "                \n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model) :\n",
    "        \n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None :\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            \n",
    "        elif score < self.best_score + self.delta :\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'\\n |EarlyStopping counter: {self.counter} out of {self.patience}|')\n",
    "            \n",
    "            # early stopping\n",
    "            if self.counter >= self.patience :\n",
    "                self.early_stop = True\n",
    "        \n",
    "        else :\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "        \n",
    "    #save checkpoint\n",
    "    def save_checkpoint (self, val_loss, model) :\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'\\nValidation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbac93",
   "metadata": {},
   "source": [
    "## Training preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d69e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8bbb10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "model = CNN().to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr= lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903764d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb99a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function looping\n",
    "def looping(mode, dataset, dataloader, model, criterion, optimizer, device) :\n",
    "    if mode ==\"train\" :\n",
    "        model.train()\n",
    "    \n",
    "    elif mode ==\"val\" or mode == \"test\":\n",
    "        model.eval()\n",
    "    \n",
    "    cost = correct = 0\n",
    "    for feature, target in tqdm(dataloader, desc=mode.title()) :\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "        output = model(feature)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        if mode ==\"train\" :\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        cost += loss.item() * feature.shape[0]\n",
    "        correct += (output.argmax(1) == target).sum().item()\n",
    "        \n",
    "    cost = cost / len(dataset)\n",
    "    acc = correct / len(dataset)\n",
    "    \n",
    "    return cost, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcdd17e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #test\n",
    "\n",
    "# epochs = 12\n",
    "# train_cost, val_cost = [], []\n",
    "# train_acc, val_acc = [], []\n",
    "# for i in range (epochs) :\n",
    "#     since = time.time()\n",
    "    \n",
    "#     # training for data train\n",
    "#     cost, acc = looping(\"train\", train_set, train_loader, model, criterion, optimizer, device)\n",
    "#     train_cost.append(cost)\n",
    "#     train_acc.append(acc)\n",
    "    \n",
    "#     # training for data val\n",
    "#     with torch.no_grad() :\n",
    "#         cost, acc = looping(\"val\", val_set, val_loader, model, criterion, optimizer, device)\n",
    "#         val_cost.append(cost)\n",
    "#         val_acc.append(acc)\n",
    "    \n",
    "#     print(\"Epochs : {}/{} | \".format(i+1, epochs),\n",
    "#           \"train_cost : {} | \".format(train_cost[-1]),\n",
    "#           \"val_cost : {} | \".format(val_cost[-1]),\n",
    "#           \"train_acc : {} | \".format(train_acc[-1]),\n",
    "#           \"val_cost : {} | \".format(val_cost[-1]),\n",
    "#           'time {:.3f} s'.format(time.time() - since)\n",
    "#          )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead17ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test - 2\n",
    "\n",
    "train_cost, val_cost = [], []\n",
    "train_acc, val_acc = [], []\n",
    "\n",
    "#object early_stopping\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
    "\n",
    "epoch = 1\n",
    "while True :\n",
    "    since = time.time()\n",
    "    \n",
    "    # training for data train\n",
    "    cost, acc = looping(\"train\", train_set, train_loader, model, criterion, optimizer, device)\n",
    "    train_cost.append(cost)\n",
    "    train_acc.append(acc)\n",
    "    \n",
    "    # training for data val\n",
    "    with torch.no_grad() :\n",
    "        cost, acc = looping(\"val\", val_set, val_loader, model, criterion, optimizer, device)\n",
    "        val_cost.append(cost)\n",
    "        val_acc.append(acc)\n",
    "        \n",
    "    print(\"Epochs : {} | \".format(epoch),\n",
    "          \"train_cost : {} | \".format(train_cost[-1]),\n",
    "          \"val_cost : {} | \".format(val_cost[-1]),\n",
    "          \"train_acc : {} | \".format(train_acc[-1]),\n",
    "          \"val_acc : {} | \".format(val_acc[-1]),\n",
    "          'time {:.3f} s'.format(time.time() - since)\n",
    "         )\n",
    "    epoch+=1\n",
    "    \n",
    "    early_stopping(val_cost[-1], model)\n",
    "    #ealry stopping\n",
    "    if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b25bae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Model \n",
    "model.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bcf740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1061c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038f4c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aac271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
